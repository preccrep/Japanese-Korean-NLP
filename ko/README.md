# Tokenization

```
> cd tokenization
> python tokenizer.py
```

I use `stopwords.txt` to remove stopwords, but you can also use `stopwords_more_comprehensive.txt` which contains more comprehensive information.

# Keywords Extraction

```
> cd keywords_extraction
> python get_top_n_keywords.py
```

You can modify `n` in the file. You can also run the `get_keywords_summarized_edition.py` to get the top 100 keywords.

There is also a file named `get_sentences.py` which can be used to extract sentences, but the project does not use it. It's just an example of how to use the functions.

